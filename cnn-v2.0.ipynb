{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport random\n\nimport gc\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm\n\nfrom PIL import Image\nimport PIL.Image\nPIL.Image.MAX_IMAGE_PIXELS = 9000000000000\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\n\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback\n\n\nimport openslide\nfrom openslide import OpenSlide\n\n# remove cap for image reading\nos.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\nimport cv2 # import after setting OPENCV_IO_MAX_IMAGE_PIXELS","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-02T20:42:37.195477Z","iopub.execute_input":"2023-01-02T20:42:37.195958Z","iopub.status.idle":"2023-01-02T20:42:47.669589Z","shell.execute_reply.started":"2023-01-02T20:42:37.195859Z","shell.execute_reply":"2023-01-02T20:42:47.668210Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# To-do:\n\n + Create a new convergence system:\n > The system should have a log(n) time complexity\n + Define the boundaries of each iamge.  Weight if it is better to have a fixed initial window size or make the intial window dependent on the image size\n + Edit the loss scoring method and let it score higher when you find nucleoids + redcells + fat tissue\n ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')\ntest = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:47.671834Z","iopub.execute_input":"2023-01-02T20:42:47.672642Z","iopub.status.idle":"2023-01-02T20:42:47.705840Z","shell.execute_reply.started":"2023-01-02T20:42:47.672600Z","shell.execute_reply":"2023-01-02T20:42:47.704713Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# add pic file_path\ntrain['file_path'] = train['image_id'].apply(lambda x: '../input/mayo-clinic-strip-ai/train/' + x + '.tif')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:47.707707Z","iopub.execute_input":"2023-01-02T20:42:47.708482Z","iopub.status.idle":"2023-01-02T20:42:47.753097Z","shell.execute_reply.started":"2023-01-02T20:42:47.708430Z","shell.execute_reply":"2023-01-02T20:42:47.751673Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   image_id  center_id patient_id  image_num label  \\\n0  006388_0         11     006388          0    CE   \n1  008e5c_0         11     008e5c          0    CE   \n2  00c058_0         11     00c058          0   LAA   \n3  01adc5_0         11     01adc5          0   LAA   \n4  026c97_0          4     026c97          0    CE   \n\n                                          file_path  \n0  ../input/mayo-clinic-strip-ai/train/006388_0.tif  \n1  ../input/mayo-clinic-strip-ai/train/008e5c_0.tif  \n2  ../input/mayo-clinic-strip-ai/train/00c058_0.tif  \n3  ../input/mayo-clinic-strip-ai/train/01adc5_0.tif  \n4  ../input/mayo-clinic-strip-ai/train/026c97_0.tif  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>center_id</th>\n      <th>patient_id</th>\n      <th>image_num</th>\n      <th>label</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>006388_0</td>\n      <td>11</td>\n      <td>006388</td>\n      <td>0</td>\n      <td>CE</td>\n      <td>../input/mayo-clinic-strip-ai/train/006388_0.tif</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>008e5c_0</td>\n      <td>11</td>\n      <td>008e5c</td>\n      <td>0</td>\n      <td>CE</td>\n      <td>../input/mayo-clinic-strip-ai/train/008e5c_0.tif</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00c058_0</td>\n      <td>11</td>\n      <td>00c058</td>\n      <td>0</td>\n      <td>LAA</td>\n      <td>../input/mayo-clinic-strip-ai/train/00c058_0.tif</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01adc5_0</td>\n      <td>11</td>\n      <td>01adc5</td>\n      <td>0</td>\n      <td>LAA</td>\n      <td>../input/mayo-clinic-strip-ai/train/01adc5_0.tif</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>026c97_0</td>\n      <td>4</td>\n      <td>026c97</td>\n      <td>0</td>\n      <td>CE</td>\n      <td>../input/mayo-clinic-strip-ai/train/026c97_0.tif</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"joo = ['09644e_0', '008e5c_0', '00c058_0', '09644e_2', '09644e_1']\ntrain[train['image_id'].isin(joo)]","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:47.756312Z","iopub.execute_input":"2023-01-02T20:42:47.757529Z","iopub.status.idle":"2023-01-02T20:42:47.783733Z","shell.execute_reply.started":"2023-01-02T20:42:47.757485Z","shell.execute_reply":"2023-01-02T20:42:47.782382Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"    image_id  center_id patient_id  image_num label  \\\n1   008e5c_0         11     008e5c          0    CE   \n2   00c058_0         11     00c058          0   LAA   \n25  09644e_0         10     09644e          0    CE   \n26  09644e_1         10     09644e          1    CE   \n27  09644e_2         10     09644e          2    CE   \n\n                                           file_path  \n1   ../input/mayo-clinic-strip-ai/train/008e5c_0.tif  \n2   ../input/mayo-clinic-strip-ai/train/00c058_0.tif  \n25  ../input/mayo-clinic-strip-ai/train/09644e_0.tif  \n26  ../input/mayo-clinic-strip-ai/train/09644e_1.tif  \n27  ../input/mayo-clinic-strip-ai/train/09644e_2.tif  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>center_id</th>\n      <th>patient_id</th>\n      <th>image_num</th>\n      <th>label</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>008e5c_0</td>\n      <td>11</td>\n      <td>008e5c</td>\n      <td>0</td>\n      <td>CE</td>\n      <td>../input/mayo-clinic-strip-ai/train/008e5c_0.tif</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00c058_0</td>\n      <td>11</td>\n      <td>00c058</td>\n      <td>0</td>\n      <td>LAA</td>\n      <td>../input/mayo-clinic-strip-ai/train/00c058_0.tif</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>09644e_0</td>\n      <td>10</td>\n      <td>09644e</td>\n      <td>0</td>\n      <td>CE</td>\n      <td>../input/mayo-clinic-strip-ai/train/09644e_0.tif</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>09644e_1</td>\n      <td>10</td>\n      <td>09644e</td>\n      <td>1</td>\n      <td>CE</td>\n      <td>../input/mayo-clinic-strip-ai/train/09644e_1.tif</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>09644e_2</td>\n      <td>10</td>\n      <td>09644e</td>\n      <td>2</td>\n      <td>CE</td>\n      <td>../input/mayo-clinic-strip-ai/train/09644e_2.tif</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def periodic(val):\n    wave = np.cos(2 * np.pi * 1/800 * val + 1/8 * np.pi) + 2\n    return wave","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:47.785736Z","iopub.execute_input":"2023-01-02T20:42:47.786259Z","iopub.status.idle":"2023-01-02T20:42:47.795819Z","shell.execute_reply.started":"2023-01-02T20:42:47.786187Z","shell.execute_reply":"2023-01-02T20:42:47.794319Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_loss(region):\n    mat = np.array(region)/255.\n    # treshold of squares colors\n    tresh = 1.2\n    # treshold of the thickness of the edge:\n    edge = 0.5\n    # number of good choices\n    good = 0\n    N = mat.shape\n    # resolution of the region (should be kept fixed)\n    x_n, y_n = N[0], N[1]\n    n_l = (np.ceil(x_n * 0.01), np.ceil(y_n * 0.01)) # check for 1% of the total image\n    good2 = False\n    # start\n    x = 0\n    y = 0\n    # step \n    step = (x_n/n_l[0], y_n/n_l[1])\n    for i in range(int(n_l[0])):\n        y = 0\n        pos_x = i * step[0]\n        for j in range(int(n_l[1])):\n            pos_y = j * step[1]\n            # pick different values for the coordinates\n            pixel = mat[x, y]\n            \n            # calculate the cost: check if the pixel in position x, y is not white\n            res = np.sqrt(pixel[1]**2 + pixel[2]**2) + 0.1/pixel[0]\n            \n            if res <= tresh:\n                good2 = True\n                good += 1\n            wave = periodic(pos_y)\n            y += int(step[1] * 0.5 * wave)\n        wave = periodic(pos_x)\n        x += int(step[0] * 0.5 * (wave))\n    # return the fraction of good pixels in the region\n    res = good/max(n_l)\n    if res >= 0.2:\n        return res\n    return 0","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:47.797782Z","iopub.execute_input":"2023-01-02T20:42:47.799029Z","iopub.status.idle":"2023-01-02T20:42:47.813582Z","shell.execute_reply.started":"2023-01-02T20:42:47.798966Z","shell.execute_reply":"2023-01-02T20:42:47.812285Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# return the ammount of blood (in fraction) in a 5k x 5k region\ndef check_big_window(slide, start_point):\n    # fraction of the region with dark clothes of blood\n    point = start_point.copy()\n    loss = 0\n    n = 5\n    \n    max_r = 1\n    m_region = [1, 2, 3]\n    for i in range(n):\n        point[0] = start_point[0]\n        for j in range(n):\n            region = (point[0] + 100, point[1] + 100)\n            window = slide.read_region(region, 0, (800, 800))\n            loss = get_loss(window)\n            point[0] += 1000\n            if loss >= max_r:\n                max_r = loss\n                m_region = region\n                \n        point[1] += 1000\n    \n    return max_r, m_region","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:47.815628Z","iopub.execute_input":"2023-01-02T20:42:47.816195Z","iopub.status.idle":"2023-01-02T20:42:47.832621Z","shell.execute_reply.started":"2023-01-02T20:42:47.816146Z","shell.execute_reply":"2023-01-02T20:42:47.831197Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def function(path, n_pixels = 3.6e6, window_size = (100, 100)):\n    # get width and height of image\n    _ = PIL.Image.open(path)\n    width, height = _.size\n    \n    # Number of windows \n    n_windows = int(n_pixels / (window_size[0] * window_size[1]))\n    \n    # number of pixels between each (window_size) window\n    step = ((width - window_size[0] * n_windows) / n_windows , (height - window_size[1] * n_windows) / n_windows)\n    print(step)\n    #  ----------------------------\n    \n    starting = [500, 500]\n    MAX_LOSS = 1\n    MAX_REGION = [1,1,1]\n    avg = 0\n    rows = []\n    for i in range(5):\n#         print(f\"Window of row: {i}\")\n        for j in range(5):\n            max_r, m_region = check_big_window(slide, starting)\n            if MAX_LOSS <= max_r:\n                MAX_LOSS = max_r\n                MAX_REGION = m_region\n\n            starting[0] += 5000\n        starting[1] += 5000\n        \n    return MAX_LOSS, MAX_REGION","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-02T20:42:47.834522Z","iopub.execute_input":"2023-01-02T20:42:47.835285Z","iopub.status.idle":"2023-01-02T20:42:47.848527Z","shell.execute_reply.started":"2023-01-02T20:42:47.835211Z","shell.execute_reply":"2023-01-02T20:42:47.847059Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"varios = train[train['label'] == 'CE'].iloc[0:2].file_path.to_numpy()\nvarios = np.concatenate([varios, train[train['label'] == 'LAA'].iloc[0:2].file_path.to_numpy()])\nvarios","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:47.851341Z","iopub.execute_input":"2023-01-02T20:42:47.852239Z","iopub.status.idle":"2023-01-02T20:42:47.872252Z","shell.execute_reply.started":"2023-01-02T20:42:47.852166Z","shell.execute_reply":"2023-01-02T20:42:47.869500Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array(['../input/mayo-clinic-strip-ai/train/006388_0.tif',\n       '../input/mayo-clinic-strip-ai/train/008e5c_0.tif',\n       '../input/mayo-clinic-strip-ai/train/00c058_0.tif',\n       '../input/mayo-clinic-strip-ai/train/01adc5_0.tif'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nsample_train = train[:20]\nregions = []\nlosses = []\n\nvarios = train[train['label'] == 'CE'].iloc[0:5].file_path.to_numpy()\nvarios = np.concatenate([varios, train[train['label'] == 'LAA'].iloc[0:5].file_path.to_numpy()])\n\nim = PIL.Image.open(varios[0])\nprint(im.size)\n\n# the default max_size of pics is 30_000 x 30_000\nfor i in varios:\n    path = i\n#     slide = OpenSlide(path)\n    loss, region = function(path)\n    print(f\"Pic {path}\")\n    window = slide.read_region(region, 0, (800, 800))\n    print(loss, region)\n    plt.figure(figsize = (8, 8))\n    plt.imshow(window)\n    plt.show()\n    size = (800, 800)\n    x = 500\n    y = 500\n    print(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2023-01-02T20:42:49.042332Z","iopub.execute_input":"2023-01-02T20:42:49.042772Z","iopub.status.idle":"2023-01-02T20:42:52.247800Z","shell.execute_reply.started":"2023-01-02T20:42:49.042734Z","shell.execute_reply":"2023-01-02T20:42:52.244283Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(34007, 60797)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in double_scalars\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/2350630356.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(slide)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         print(f\"Window of row: {i}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmax_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_big_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mMAX_LOSS\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_r\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mMAX_LOSS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/2006130455.py\u001b[0m in \u001b[0;36mcheck_big_window\u001b[0;34m(slide, start_point)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openslide/__init__.py\u001b[0m in \u001b[0;36mread_region\u001b[0;34m(self, location, level, size)\u001b[0m\n\u001b[1;32m    235\u001b[0m         function is not premultiplied.\"\"\"\n\u001b[1;32m    236\u001b[0m         return lowlevel.read_region(\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_osr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         )\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openslide/lowlevel.py\u001b[0m in \u001b[0;36mread_region\u001b[0;34m(slide, x, y, level, w, h)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_uint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     \u001b[0m_read_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/openslide/lowlevel.py\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(result, func, args)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;31m# check if the library got into an error state after each library call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# directly process the data\ndef process(path):\n    size  = (800, 800)\n    slide = OpenSlide(path)\n    loss, region = function(slide)\n    image = slide.read_region(region, 0, size)\n    plt.figure(figsize = (8, 8))\n    plt.imshow(image)\n    plt.show()\n    image = tf.image.resize(image, (512, 512))\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []\nfor path in tqdm(train['file_path']):\n    print(f\"Processing {path}\")\n    image = process(path)\n    X.append(image)\n    name = path.split(\"/\")[-1]\n    tf.keras.utils.save_img(f\"/kaggle/working/processed/{name}\", image)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toy = train.copy()\nfiles = []\npaths = os.scandir(\"/kaggle/working/processed\")\nfor part in paths:\n    if part.is_file() and (part.name.find(\"tif\") > 0):\n        files.append(part.name)\n        \n\ntoy = toy.set_index('image_id')\n\nfor file in files:\n    print()\n    name = file.split(\".\")[0]\n    label = toy.loc[name, 'label']\n    print(name, label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def step_decay(epoch):\n    initial_lrate = 0.001\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * drop ** np.floor((epoch)/epochs_drop)\n    return lrate\n\nl_rate = LearningRateScheduler(step_decay)\nearstop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shapes = (512, 512, 4)\n\ninput_layer = layers.Input(name = 'input', shape = shapes)\nconv_1 = layers.Conv2D(filters=32, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu', input_shape = shapes, name = 'conv_1')(input_layer)\nconv_2 = layers.Conv2D(filters=64, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu', name = 'conv_2')(conv_1)\nconv_3 = layers.Conv2D(filters=32, kernel_size = (3,3), strides =2, padding = 'same', activation = 'relu', name = 'conv_3')(conv_2)\nflat = layers.Flatten()(conv_3)\nh1 = layers.Dense(128, activation = 'relu', name = 'h1')(flat)\ndrop = layers.Dropout(0.25)(h1)\noutput = layers.Dense(1, activation = 'sigmoid', name = 'prediction')(h1)\n\nmodel = tf.keras.Model(input_layer, output)\n\nmodel.compile(optimizer = 'adam', \n                loss = tf.keras.losses.BinaryCrossentropy(), \n                 metrics = ['accuracy', 'mse', 'mape']\n             )\n\ntf.keras.utils.plot_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = train['label'].unique().tolist()\nY = train['label'].apply(lambda x: vocab.index(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret = pd.DataFrame((X, Y)).transpose()\nret.columns = ['input', 'label']\nret.to_csv('processed.csv', index = False, header = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndataset = pd.read_csv('processed.csv')\ntrain, test = train_test_split(dataset, test_size = 0.2)\ntrain, val = train_test_split(dataset, test_size = 0.2)\n\ntrain = tf.data.Dataset.from_tensor_slices((dict(train))).batch(BATCH_SIZE)\nval = tf.data.Dataset.from_tensor_slices((dict(val))).batch(BATCH_SIZE)\ntest = tf.data.Dataset.from_tensor_slices((dict(test))).batch(1)\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train.take(1):\n    print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 20\nSTEPS_X_EPOCH = 2\nhistory = model.fit(train, validation_data = val, epochs = EPOCHS, callbacks = [l_rate, earstop])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_df)\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = y_test.to_numpy()\ny_ = []\nfor i in pred:\n    i_r = i.round()\n    if i_r >= 1:\n        y_.append(1)\n    else:\n        y_.append(0)\n\nprint(f\" Accuracy: {1 - sum(abs(y - y_))/len(y_)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for __ in test_df.take(1):\n    print(__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}